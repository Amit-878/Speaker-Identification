
# ğŸ™ï¸ Speaker Identification with WhisperX + SpeechBrain

Automatically transcribe meetings and assign **real speaker names** using reference audio files.
This project combines:

* **[WhisperX](https://github.com/m-bain/whisperX)** â†’ Fast, accurate speech recognition + forced alignment
* **[SpeechBrain](https://speechbrain.github.io/)** â†’ Speaker verification (ECAPA-TDNN)
* **PyTorch** â†’ Deep learning backend

---

## ğŸš€ Features

âœ… Transcribes meeting audio using **WhisperX**
âœ… Aligns timestamps with word-level precision
âœ… Performs **speaker diarization** (who spoke when)
âœ… Identifies speakers using **reference voice samples**
âœ… Exports transcript in **speaker-labeled text file**

Example Output:

```
[Amit]: Good morning everyone, let's start the meeting.  
[Shivali]: Yes, I wanted to share an update on the project.  
[Unknown]: Sorry, could you repeat that?  
```

---

## ğŸ“‚ Project Structure

```
speaker-identification/
â”‚â”€â”€ main.py                # Entry point
â”‚â”€â”€ requirements.txt       # Dependencies
â”‚â”€â”€ README.md              # Documentation
â”‚â”€â”€ config/
â”‚   â””â”€â”€ references.json    # Reference speakers and their audio
â”‚â”€â”€ utils/
â”‚   â”œâ”€â”€ speaker_utils.py   # Speaker recognition helper functions
â”‚   â”œâ”€â”€ audio_utils.py     # Audio segmentation helpers
â”‚â”€â”€ outputs/
â”‚   â”œâ”€â”€ MeetingResult.txt  # Transcript results
```

---

## âš™ï¸ Setup Instructions

### 1ï¸âƒ£ Clone the repository

```bash
git clone https://github.com/your-username/speaker-identification.git
cd speaker-identification
```

### 2ï¸âƒ£ Create & activate virtual environment (recommended)

```bash
python -m venv venv
source venv/bin/activate   # Mac/Linux
venv\Scripts\activate      # Windows
```

### 3ï¸âƒ£ Install dependencies

```bash
pip install -r requirements.txt
```

> âš ï¸ Make sure you have **Python 3.9+** and **PyTorch** installed.
> If `torch` doesnâ€™t install automatically, follow [PyTorch installation guide](https://pytorch.org/get-started/locally/).

### 4ï¸âƒ£ Hugging Face Token (required for diarization)

1. Create a free account on [Hugging Face](https://huggingface.co/join).
2. Get your **access token** from [settings/tokens](https://huggingface.co/settings/tokens).
3. Open `main.py` and replace:

   ```python
   HF_TOKEN = "your_hf_token_here"
   ```

---

## ğŸ¤ Usage

### 1ï¸âƒ£ Prepare your audio

* Place your meeting audio file in the project root (e.g., `meeting.wav`) or provide the path when executing the code.
* Recommended format: `.wav` (16kHz mono for best results).

### 2ï¸âƒ£ Add reference speakers

Edit `config/references.json`:

```json
{
  "Amit": "refs/amit.wav",
  "Shivali": "refs/shivali.wav",
  "Mudit": "refs/mudit.wav"
}
```

ğŸ‘‰ Each key is a **speaker name**, each value is the **path to their sample audio**.
ğŸ‘‰ Sample clips should be at least **10 seconds** for best accuracy.

### 3ï¸âƒ£ Run transcription + speaker labeling 

```bash
python main.py your_audio_file.wav
```

### 4ï¸âƒ£ View results

Transcript with speaker names will be saved in:

```
outputs/MeetingResult.txt
```

---

## ğŸ§  Models Used

### ğŸ§ WhisperX

* Based on [OpenAI Whisper](https://github.com/openai/whisper)
* Supports **word-level alignment**
* Used for **speech-to-text**

### ğŸ—£ï¸ SpeechBrain ECAPA-TDNN

* Model: `speechbrain/spkrec-ecapa-voxceleb`
* Used for **speaker verification**
* Compares diarized segments to **reference audios**

### ğŸ”Š PyTorch + Librosa + SoundFile

* Audio preprocessing & segment extraction

---

## ğŸ› ï¸ Example Workflow

1. Input: `meeting.wav` in the base directory.
2. WhisperX â†’ Transcribe + align words
3. Diarization â†’ Split speakers
4. Speaker verification â†’ Match with reference audios
5. Output: `MeetingResult.txt` with **real names**

---

## ğŸ“Œ Example Reference File (`config/references.json`)

```json
{
    "Amit": "refs/amit.wav",
    "Chirag": "refs/chirag.wav",
    "Shivali": "refs/shivali.wav"
}
```

---

## ğŸ“‹ Requirements

* Python 3.9+
* torch >= 2.0
* whisperx
* speechbrain
* librosa
* numpy
* soundfile
* scipy
* transformers

(Already included in `requirements.txt`)

---

## ğŸ¤ Contributing

Pull requests are welcome!
If you find a bug or want a feature, open an issue.

---

## ğŸ“œ License

This project is licensed under the **MIT License** â€“ feel free to use and modify.

